{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bcb027-c955-4a54-bb0e-902fe4fc2f17",
   "metadata": {},
   "source": [
    "# Comparando audios con descriptores MFCC\n",
    "\n",
    "**Curso**: CC5213 - Recuperación de Información Multimedia  \n",
    "**Profesor**: Juan Manuel Barrios  \n",
    "**Fecha**: 15 de abril de 2025\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089a92c-a728-49dc-b60e-6b9b0b07a192",
   "metadata": {},
   "source": [
    "\n",
    " Para calcular descriptores de un audio vamos a usar la librería **LibROSA**. Instalar con:\n",
    " \n",
    " ```\n",
    " pip install librosa\n",
    " ```\n",
    "\n",
    "NO USAR `conda install librosa` porque fallará por un error de versiones de librerías (al menos la versión para windows).\n",
    "\n",
    "LibROSA puede leer archivos de audio formato `wav`. Ver https://librosa.org/doc/main/generated/librosa.load.html:\n",
    "\n",
    "```\n",
    "    samples, sample_rate = librosa.load(archivo_wav, sr=None)\n",
    "```\n",
    "\n",
    "El argumento `sr` es el sample_rate que se desea leer los samples. Por defecto usa `sr=22050`  (hace una conversion). Con `sr=None` usar el mismo sample_rate del archivo wav.\n",
    "\n",
    "Para convertir cualquier audio o video a wav usaremos FFmpeg.\n",
    "\n",
    "Para calcular descriptores usaremos la implementación de MFCC de LibROSA https://librosa.org/doc/main/generated/librosa.feature.mfcc.html:\n",
    "\n",
    "```\n",
    "    matriz = librosa.feature.mfcc(y=samples, sr=sr, n_mfcc=dimension, n_fft=ventana, hop_length=salto)\n",
    "    descriptores_mfcc = matriz.transpose()\n",
    "```\n",
    "\n",
    " * `n_mfcc` es la dimensión de los descriptores a calcular (cantidad de canales a representar). Usualmente un número entre 20 y 30.\n",
    " * `n_fft` es el tamaño de ventana a representar (cantidad de samples). Idealmente debe ser potencia de 2 (e.g. 512, 1024, 2048, 4096, 8192) para que el cálculo de la Transformada de Fourier sea rápido.\n",
    " * `hop_length` es la cantidad de samples a desplazarse para calcular el siguiente descriptor. Puede ser el mismo número `n_fft` para no tener traslape o `n_fft/2` para tener un traslape de la mitad de la ventana.\n",
    "\n",
    "Notar que LibROSA retorna **descriptores como columnas**, pero comúnmente para calcular distancias los descriptores se usan como filas, por lo que es recomendable llamar a la función `transpose()` para retornarlos como fila.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737b2e8-ff99-44b5-b8da-ee9cdff658fd",
   "metadata": {},
   "source": [
    "# Ejemplo 1: Calcular descriptores MFCC de un archivo de audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae6cfe-6287-4947-8662-32530363e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os.path\n",
    "import subprocess\n",
    "import librosa\n",
    "\n",
    "\n",
    "#funcion que recibe un nombre de archivo y llama a FFmpeg para crear un archivo raw\n",
    "def convertir_a_wav(filename, sample_rate, carpeta_temporal):\n",
    "    archivo_wav = \"{}/{}.{}.wav\".format(carpeta_temporal, os.path.basename(filename), sample_rate) \n",
    "    if os.path.isfile(archivo_wav):\n",
    "        return archivo_wav\n",
    "    os.makedirs(carpeta_temporal, exist_ok=True)\n",
    "    print(\"convertir {} a {}  samplerate {}\".format(filename, archivo_wav, sample_rate))\n",
    "    comando = [\"ffmpeg\", \"-i\", filename, \"-ac\", \"1\", \"-ar\", str(sample_rate), archivo_wav]\n",
    "    print(\"  COMANDO: {}\".format(\" \".join(comando)))\n",
    "    code = subprocess.call(comando)\n",
    "    if code != 0:\n",
    "        raise Exception(\"ERROR en comando: \" + \" \".join(comando))\n",
    "    return archivo_wav\n",
    "\n",
    "    \n",
    "def calcular_descriptores_mfcc(archivo_wav, sample_rate, samples_por_ventana, samples_salto, dimension):\n",
    "    # leer audio\n",
    "    samples, sr = librosa.load(archivo_wav, sr=None)\n",
    "    print(\"audio samples={} samplerate={} segundos={:.1f}\".format(len(samples), sr, len(samples) / sr))\n",
    "    # calcular MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=samples, sr=sr, n_mfcc=dimension, n_fft=samples_por_ventana, hop_length=samples_salto)\n",
    "    # convertir a descriptores por fila\n",
    "    descriptores = mfcc.transpose()\n",
    "    # en el descriptor MFCC la primera dimensión está relacionada al volumen global del audio (energía promedio)\n",
    "    # usualmente es buena idea descartar la primera dimensión para tener descriptores invariantes al volumen global\n",
    "    return descriptores\n",
    "\n",
    "\n",
    "def calcular_mfcc_archivo(archivo_audio, sample_rate, samples_por_ventana, samples_salto, dimension, carpeta_temporal):\n",
    "    archivo_wav = convertir_a_wav(archivo_audio, sample_rate, carpeta_temporal)\n",
    "    descriptores = calcular_descriptores_mfcc(archivo_wav, sample_rate, samples_por_ventana, samples_salto, dimension)\n",
    "    return descriptores\n",
    "\n",
    "\n",
    "sample_rate = 44100         #calidad del audio (44100 es HD, se puede bajar)\n",
    "samples_por_ventana = 4096  #tamaño de la ventana a la que se calcula un descriptor MFCC (usualmente unas 5 a 10 por segundo)\n",
    "samples_salto = 4096        #se puede probar con un  el salto es menor al tamaño de la ventana para que haya traslape entre ventanas\n",
    "dimension = 10              #largo del descriptor MFCC (usualmente entre 10 a 64)\n",
    "\n",
    "print(\"ventana={} samples ({:.3f} segundos)\".format(samples_por_ventana, samples_por_ventana/sample_rate))\n",
    "print(\"salto  ={} samples ({:.3f} segundos)\".format(samples_salto, samples_salto/sample_rate))\n",
    "\n",
    "# donde crear archivos intermedios\n",
    "carpeta_temporal = \"audios_temporales\"\n",
    "\n",
    "archivo_audio = \"vivaldi.mp3\"\n",
    "descriptores_mfcc = calcular_mfcc_archivo(archivo_audio, sample_rate, samples_por_ventana, samples_salto, dimension, carpeta_temporal)\n",
    "\n",
    "print()\n",
    "print(\"matriz de descriptores MFCC\")\n",
    "print(\"  filas={} columnas={} tipo={}\".format(descriptores_mfcc.shape[0], descriptores_mfcc.shape[1], descriptores_mfcc.dtype))\n",
    "\n",
    "descriptores_mfcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35249be2-afd3-478b-ad18-c3b56721c812",
   "metadata": {},
   "source": [
    "# Ejemplo 2: Buscar segmentos de audios conocidos dentro de un audio desconocido\n",
    "\n",
    "## 2.a) Primero se calculan descriptores de los audios conocidos (conjunto R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83159a-ea93-486b-9eda-83d254f5bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ventana:\n",
    "    def __init__(self, nombre_archivo, segundos_desde, segundos_hasta):\n",
    "        self.nombre_archivo = nombre_archivo\n",
    "        self.segundos_desde = segundos_desde\n",
    "        self.segundos_hasta = segundos_hasta\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"{} [{:6.3f}-{:6.3f}]\".format(self.nombre_archivo, self.segundos_desde, self.segundos_hasta)\n",
    "\n",
    "def lista_ventanas(nombre_archivo, numero_descriptores, sample_rate, samples_por_ventana):\n",
    "    # tantas ventanas como numero de descriptores\n",
    "    tiempos = []\n",
    "    for i in range(0, samples_por_ventana * numero_descriptores, samples_por_ventana):\n",
    "        # tiempo de inicio de la ventana\n",
    "        segundos_desde = i / sample_rate\n",
    "        # tiempo de fin de la ventana\n",
    "        segundos_hasta = (i + samples_por_ventana - 1) / sample_rate\n",
    "        # crear objeto\n",
    "        v = Ventana(nombre_archivo, segundos_desde, segundos_hasta)\n",
    "        # agregar a la lista\n",
    "        tiempos.append(v)\n",
    "    return tiempos\n",
    "\n",
    "\n",
    "def calcular_mfcc_varios_archivos(lista_archivos, sample_rate, samples_por_ventana, samples_salto, dimension, carpeta_temporal):\n",
    "    descriptores_mfcc = []\n",
    "    descriptores_ventanas = []\n",
    "    for nombre_archivo in lista_archivos:\n",
    "        audio_mfcc = calcular_mfcc_archivo(nombre_archivo, sample_rate, samples_por_ventana, samples_salto, dimension, carpeta_temporal)\n",
    "        audio_ventanas = lista_ventanas(nombre_archivo, audio_mfcc.shape[0], sample_rate, samples_por_ventana)\n",
    "        print(\"  descriptores: {}\".format(audio_mfcc.shape))\n",
    "        if len(descriptores_mfcc) == 0:\n",
    "            descriptores_mfcc = audio_mfcc\n",
    "        else:\n",
    "            # agregar como filas\n",
    "            descriptores_mfcc = numpy.vstack([descriptores_mfcc, audio_mfcc])\n",
    "        # agregar al final\n",
    "        descriptores_ventanas.extend(audio_ventanas)\n",
    "    return descriptores_ventanas, descriptores_mfcc\n",
    "   \n",
    "def imprimir_ventanas(ventanas, mfcc, muestreo_ventanas=1):\n",
    "    print(\"ventanas={} descriptores={}\".format(len(ventanas), mfcc.shape))\n",
    "    print(\"mostrando algunas ventanas:\")\n",
    "    for i in range(0, len(ventanas), muestreo_ventanas):\n",
    "        print(\" {:4d}) {} descriptor={}\".format(i, ventanas[i], mfcc[i].shape))\n",
    "    \n",
    "archivos_conocidos = [\"vivaldi.mp3\", \"jaivas.mp3\"]\n",
    "\n",
    "ventanas_conocidos, mfcc_conocidos = calcular_mfcc_varios_archivos(archivos_conocidos, sample_rate, samples_por_ventana, samples_salto, dimension, carpeta_temporal)\n",
    "\n",
    "#escribir los descriptores de audios conocidos\n",
    "print()\n",
    "print(\"descriptores conocidos\")\n",
    "imprimir_ventanas(ventanas_conocidos, mfcc_conocidos, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78631d6-b9e2-42bc-b356-b33a749c9c5a",
   "metadata": {},
   "source": [
    "## 2.b) Se calculan descriptores de un audio desconocido (conjunto Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740ae78-8f61-4600-ab01-2ed6b7eea3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio consulta\n",
    "query_archivo = \"varios.mp3\"\n",
    "\n",
    "ventanas_query, mfcc_query = calcular_mfcc_varios_archivos([query_archivo], sample_rate, samples_por_ventana, samples_salto, dimension, carpeta_temporal)\n",
    "\n",
    "print(\"Query: ventanas={} descriptores={}\".format(len(ventanas_query), mfcc_query.shape))\n",
    "#escribir los descriptores de audios conocidos\n",
    "print()\n",
    "print(\"descriptores audio desconocido\")\n",
    "imprimir_ventanas(ventanas_query, mfcc_query, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed6f8e-6125-456b-839b-91e9239cb237",
   "metadata": {},
   "source": [
    "## 2.c) Comparar descriptores del audio desconocido (Q) con los descriptores de los audios conocidos (R)\n",
    "\n",
    "Con cdist se comparan todos los descriptores de Q contra todos los descriptores de R y entrega la matriz de distancias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9620df-a17f-474c-92af-a7c5fb0a1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "matriz_distancias = scipy.spatial.distance.cdist(mfcc_query, mfcc_conocidos, metric='euclidean')\n",
    "print(matriz_distancias.shape)\n",
    "matriz_distancias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d3c8c-a051-4cca-918f-b69f9516f1a2",
   "metadata": {},
   "source": [
    "## 2.d) Para cada descriptor de Q mostrar la ventana más parecida de R\n",
    "\n",
    "Cada ventana se identifica por el nombre del archivo y el intervalo de tiempo que representa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa8e66-e4a4-4461-9f1b-439ab2952680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtener la posicion del mas cercano por fila\n",
    "posicion_min = numpy.argmin(matriz_distancias, axis=1)\n",
    "minimo = numpy.amin(matriz_distancias, axis=1)\n",
    "\n",
    "for i in range(len(ventanas_query)):\n",
    "    query = ventanas_query[i]\n",
    "    conocido = ventanas_conocidos[posicion_min[i]]\n",
    "    diferencia = (conocido.segundos_desde - query.segundos_desde)\n",
    "    print(\" {:4d}) {} se parece a  {}    (diferencia de tiempos={:4.1f} seg.)\".format(i, query, conocido, diferencia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d937ef-cdcf-4f0d-bd1e-c8de48b38f2c",
   "metadata": {},
   "source": [
    "Notar que  en las zonas donde hay coincidencia de audio, los tiempos de ambas ventanas van avanzando al mismo tiempo, es decir, la diferencia entre los tiempos de sus ventanas `conocido.segundos_desde - query.segundos_desde` se mantiene constante.  \n",
    "\n",
    "Si se agrupan las diferencias de tiempo que más se repiten, se pueden localizar las regiones comunes entre audios.\n",
    "\n",
    "Por ejemplo, viendo la lista anterior se puede concluir que:\n",
    "\n",
    " * En `varios.mp3` entre [0.279 y 5.759] se escucha el audio de `vivaldi.mp3` entre los segundos 47.926 y 53.313 (es decir, tienen un desfase de 47.6 segundos).\n",
    " * En `varios.mp3` entre [5.851 y 8.916] se escucha `jaivas.mp3` entre [29.536 y 32.601]  (es decir, tienen un desfase de 23.7 segundos)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed12ae-af10-4b1b-bbf4-12f0c721ba34",
   "metadata": {},
   "source": [
    "## 2.e) Votación entre ventanas parecidas para encontrar zonas que coinciden\n",
    "\n",
    "Se buscan las zonas donde se repita más el trio (audioQ, audioR, offset). Se usará un diccionario y se acumularán votos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144aecb-12e6-4091-9fe4-25112162fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Votos:\n",
    "    def __init__(self, name, query, conocido):\n",
    "        self.name = name\n",
    "        self.query_nombre = query.nombre_archivo\n",
    "        self.query_inicio = query.segundos_desde\n",
    "        self.query_fin = query.segundos_hasta\n",
    "        self.conocido_nombre = conocido.nombre_archivo\n",
    "        self.conocido_inicio = conocido.segundos_desde\n",
    "        self.conocido_fin = conocido.segundos_hasta\n",
    "        self.numVotos = 1\n",
    "\n",
    "    def addVoto(self, query, conocido):\n",
    "        # muevo el final de la zona y sumo un voto\n",
    "        self.query_fin = query.segundos_hasta\n",
    "        self.conocido_fin = conocido.segundos_hasta\n",
    "        self.numVotos += 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{} entre [{:6.3f}-{:6.3f}]  se parece a  {} entre [{:6.3f}-{:6.3f}]  ({} votos)\".format(\n",
    "            self.query_nombre, self.query_inicio, self.query_fin, \n",
    "            self.conocido_nombre, self.conocido_inicio, self.conocido_fin,\n",
    "            self.numVotos)\n",
    "\n",
    "contadores = dict()\n",
    "\n",
    "for i in range(len(ventanas_query)):\n",
    "    query = ventanas_query[i]\n",
    "    conocido = ventanas_conocidos[posicion_min[i]]\n",
    "    diferencia = (conocido.segundos_desde - query.segundos_desde)\n",
    "    # llave para acumular (se podría mejorar la acumulación si la diferencia se redondea)\n",
    "    key = \"{}-{}-{:4.1f}\".format(query.nombre_archivo, conocido.nombre_archivo, diferencia)\n",
    "    # ver si hay votos anteriores\n",
    "    votos = contadores.get(key)\n",
    "    if votos is None:\n",
    "        # se inicia votacion por ese desfase\n",
    "        votos = Votos(key, query, conocido)\n",
    "        contadores[key] = votos\n",
    "    else:\n",
    "        # suma un voto a una deteccion encontrada previamente con el mismo desfase\n",
    "        votos.addVoto(query, conocido)\n",
    "\n",
    "# mostrar las mayores votaciones\n",
    "allVotos = list(contadores.values())\n",
    "for v in sorted(allVotos, key = lambda x : x.numVotos, reverse=True):\n",
    "    if v.numVotos > 20:\n",
    "        print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133cbd5-4173-48d0-82fb-6dbd53ca9445",
   "metadata": {},
   "source": [
    "## Propuesto:\n",
    "\n",
    "En la votacion anterior se encontraron dos zonas similares.\n",
    "\n",
    "Notar que `varios.mp3` tiene **cinco zonas** parecidas (tres para `vivaldi.mp3` y dos para `jaivas.mp3`)\n",
    "\n",
    "¿Se pueden detectar las cinco zonas? ¿Qué habría que modificar?\n",
    "\n",
    "Ver el material el curso de esta semana y de la semana 07 para ideas sobre cómo se puede mejorar esta detección.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
